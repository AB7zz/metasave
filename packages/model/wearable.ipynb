{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alosh\\AppData\\Local\\Temp\\ipykernel_8408\\194873407.py:4: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r'C:\\Users\\alosh\\Downloads\\CompleteDataSet.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before filtering: (294679, 47)\n",
      "Shape after filtering: (6493, 47)\n",
      "Filtered dataset has been saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(r'C:\\Users\\alosh\\Downloads\\CompleteDataSet.csv')\n",
    "\n",
    "# Print the shape of the dataset before filtering\n",
    "print(\"Shape before filtering:\", df.shape)\n",
    "\n",
    "# Filter the dataframe to keep only rows where 'Tag' is 1, 2, 3, or 4\n",
    "df_filtered = df[df['Tag'].isin([1, 2, 3, 4])]\n",
    "\n",
    "# Print the shape of the dataset after filtering\n",
    "print(\"Shape after filtering:\", df_filtered.shape)\n",
    "\n",
    "# Save the filtered dataset\n",
    "# Replace 'filtered_dataset.csv' with your desired output filename\n",
    "df_filtered.to_csv(r\"C:\\Users\\alosh\\Downloads\\filtered.csv\", index=False)\n",
    "\n",
    "print(\"Filtered dataset has been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9789, F1-score (weighted): 0.0000\n",
      "XGBoost Accuracy: 0.9798, F1-score (weighted): 0.1713\n",
      "CatBoost Accuracy: 0.9805, F1-score (weighted): 0.2026\n",
      "Gradient Boosting Accuracy: 0.9798, F1-score (weighted): 0.1263\n",
      "0:\tlearn: 0.5159123\ttotal: 1.8s\tremaining: 5m 57s\n",
      "1:\tlearn: 0.3869081\ttotal: 3.54s\tremaining: 5m 50s\n",
      "2:\tlearn: 0.3042090\ttotal: 3.59s\tremaining: 3m 56s\n",
      "3:\tlearn: 0.2439665\ttotal: 5.24s\tremaining: 4m 16s\n",
      "4:\tlearn: 0.2021104\ttotal: 6.86s\tremaining: 4m 27s\n",
      "5:\tlearn: 0.1725878\ttotal: 8.68s\tremaining: 4m 40s\n",
      "6:\tlearn: 0.1517382\ttotal: 10.6s\tremaining: 4m 51s\n",
      "7:\tlearn: 0.1360212\ttotal: 12.2s\tremaining: 4m 52s\n",
      "8:\tlearn: 0.1238132\ttotal: 13.8s\tremaining: 4m 52s\n",
      "9:\tlearn: 0.1150116\ttotal: 15.3s\tremaining: 4m 50s\n",
      "10:\tlearn: 0.1083397\ttotal: 16.8s\tremaining: 4m 49s\n",
      "11:\tlearn: 0.1033079\ttotal: 18.4s\tremaining: 4m 47s\n",
      "12:\tlearn: 0.0995494\ttotal: 19.9s\tremaining: 4m 46s\n",
      "13:\tlearn: 0.0962760\ttotal: 21.4s\tremaining: 4m 44s\n",
      "14:\tlearn: 0.0938808\ttotal: 22.9s\tremaining: 4m 42s\n",
      "15:\tlearn: 0.0921534\ttotal: 24.4s\tremaining: 4m 40s\n",
      "16:\tlearn: 0.0907884\ttotal: 25.9s\tremaining: 4m 38s\n",
      "17:\tlearn: 0.0894206\ttotal: 27.4s\tremaining: 4m 36s\n",
      "18:\tlearn: 0.0883065\ttotal: 28.9s\tremaining: 4m 35s\n",
      "19:\tlearn: 0.0872572\ttotal: 30.4s\tremaining: 4m 33s\n",
      "20:\tlearn: 0.0864298\ttotal: 31.9s\tremaining: 4m 31s\n",
      "21:\tlearn: 0.0856264\ttotal: 33.5s\tremaining: 4m 30s\n",
      "22:\tlearn: 0.0848412\ttotal: 35.5s\tremaining: 4m 32s\n",
      "23:\tlearn: 0.0844027\ttotal: 37.3s\tremaining: 4m 33s\n",
      "24:\tlearn: 0.0837926\ttotal: 39.1s\tremaining: 4m 33s\n",
      "25:\tlearn: 0.0833073\ttotal: 40.8s\tremaining: 4m 33s\n",
      "26:\tlearn: 0.0829086\ttotal: 42.4s\tremaining: 4m 31s\n",
      "27:\tlearn: 0.0826142\ttotal: 44s\tremaining: 4m 30s\n",
      "28:\tlearn: 0.0822723\ttotal: 45.6s\tremaining: 4m 28s\n",
      "29:\tlearn: 0.0818855\ttotal: 47.1s\tremaining: 4m 26s\n",
      "30:\tlearn: 0.0815276\ttotal: 48.7s\tremaining: 4m 25s\n",
      "31:\tlearn: 0.0813378\ttotal: 50.3s\tremaining: 4m 24s\n",
      "32:\tlearn: 0.0810273\ttotal: 52s\tremaining: 4m 23s\n",
      "33:\tlearn: 0.0807607\ttotal: 53.5s\tremaining: 4m 21s\n",
      "34:\tlearn: 0.0803885\ttotal: 55.1s\tremaining: 4m 19s\n",
      "35:\tlearn: 0.0801282\ttotal: 56.7s\tremaining: 4m 18s\n",
      "36:\tlearn: 0.0799174\ttotal: 58.5s\tremaining: 4m 17s\n",
      "37:\tlearn: 0.0797138\ttotal: 1m\tremaining: 4m 16s\n",
      "38:\tlearn: 0.0795054\ttotal: 1m 1s\tremaining: 4m 15s\n",
      "39:\tlearn: 0.0792843\ttotal: 1m 3s\tremaining: 4m 14s\n",
      "40:\tlearn: 0.0789871\ttotal: 1m 5s\tremaining: 4m 13s\n",
      "41:\tlearn: 0.0788459\ttotal: 1m 6s\tremaining: 4m 11s\n",
      "42:\tlearn: 0.0785938\ttotal: 1m 8s\tremaining: 4m 10s\n",
      "43:\tlearn: 0.0783263\ttotal: 1m 10s\tremaining: 4m 8s\n",
      "44:\tlearn: 0.0781646\ttotal: 1m 11s\tremaining: 4m 7s\n",
      "45:\tlearn: 0.0780112\ttotal: 1m 13s\tremaining: 4m 6s\n",
      "46:\tlearn: 0.0777489\ttotal: 1m 15s\tremaining: 4m 4s\n",
      "47:\tlearn: 0.0774816\ttotal: 1m 16s\tremaining: 4m 3s\n",
      "48:\tlearn: 0.0772396\ttotal: 1m 18s\tremaining: 4m 2s\n",
      "49:\tlearn: 0.0770398\ttotal: 1m 20s\tremaining: 4m\n",
      "50:\tlearn: 0.0767380\ttotal: 1m 21s\tremaining: 3m 59s\n",
      "51:\tlearn: 0.0765734\ttotal: 1m 23s\tremaining: 3m 57s\n",
      "52:\tlearn: 0.0763918\ttotal: 1m 24s\tremaining: 3m 55s\n",
      "53:\tlearn: 0.0761900\ttotal: 1m 26s\tremaining: 3m 53s\n",
      "54:\tlearn: 0.0760114\ttotal: 1m 28s\tremaining: 3m 52s\n",
      "55:\tlearn: 0.0757843\ttotal: 1m 29s\tremaining: 3m 51s\n",
      "56:\tlearn: 0.0755964\ttotal: 1m 31s\tremaining: 3m 49s\n",
      "57:\tlearn: 0.0754105\ttotal: 1m 32s\tremaining: 3m 47s\n",
      "58:\tlearn: 0.0752540\ttotal: 1m 34s\tremaining: 3m 45s\n",
      "59:\tlearn: 0.0750858\ttotal: 1m 36s\tremaining: 3m 44s\n",
      "60:\tlearn: 0.0749011\ttotal: 1m 37s\tremaining: 3m 42s\n",
      "61:\tlearn: 0.0747009\ttotal: 1m 39s\tremaining: 3m 41s\n",
      "62:\tlearn: 0.0744713\ttotal: 1m 40s\tremaining: 3m 39s\n",
      "63:\tlearn: 0.0743022\ttotal: 1m 42s\tremaining: 3m 37s\n",
      "64:\tlearn: 0.0741493\ttotal: 1m 43s\tremaining: 3m 35s\n",
      "65:\tlearn: 0.0739777\ttotal: 1m 45s\tremaining: 3m 34s\n",
      "66:\tlearn: 0.0737783\ttotal: 1m 46s\tremaining: 3m 32s\n",
      "67:\tlearn: 0.0736319\ttotal: 1m 48s\tremaining: 3m 30s\n",
      "68:\tlearn: 0.0735236\ttotal: 1m 50s\tremaining: 3m 28s\n",
      "69:\tlearn: 0.0733817\ttotal: 1m 51s\tremaining: 3m 27s\n",
      "70:\tlearn: 0.0732225\ttotal: 1m 53s\tremaining: 3m 25s\n",
      "71:\tlearn: 0.0730220\ttotal: 1m 54s\tremaining: 3m 23s\n",
      "72:\tlearn: 0.0728710\ttotal: 1m 56s\tremaining: 3m 22s\n",
      "73:\tlearn: 0.0727621\ttotal: 1m 58s\tremaining: 3m 20s\n",
      "74:\tlearn: 0.0726183\ttotal: 1m 59s\tremaining: 3m 19s\n",
      "75:\tlearn: 0.0724675\ttotal: 2m 1s\tremaining: 3m 18s\n",
      "76:\tlearn: 0.0723143\ttotal: 2m 2s\tremaining: 3m 16s\n",
      "77:\tlearn: 0.0721836\ttotal: 2m 4s\tremaining: 3m 14s\n",
      "78:\tlearn: 0.0720221\ttotal: 2m 6s\tremaining: 3m 13s\n",
      "79:\tlearn: 0.0719130\ttotal: 2m 7s\tremaining: 3m 11s\n",
      "80:\tlearn: 0.0717503\ttotal: 2m 9s\tremaining: 3m 10s\n",
      "81:\tlearn: 0.0715826\ttotal: 2m 11s\tremaining: 3m 8s\n",
      "82:\tlearn: 0.0714261\ttotal: 2m 12s\tremaining: 3m 6s\n",
      "83:\tlearn: 0.0713061\ttotal: 2m 14s\tremaining: 3m 5s\n",
      "84:\tlearn: 0.0711752\ttotal: 2m 16s\tremaining: 3m 4s\n",
      "85:\tlearn: 0.0710799\ttotal: 2m 17s\tremaining: 3m 2s\n",
      "86:\tlearn: 0.0709855\ttotal: 2m 19s\tremaining: 3m 1s\n",
      "87:\tlearn: 0.0708421\ttotal: 2m 21s\tremaining: 2m 59s\n",
      "88:\tlearn: 0.0707545\ttotal: 2m 22s\tremaining: 2m 58s\n",
      "89:\tlearn: 0.0706050\ttotal: 2m 24s\tremaining: 2m 56s\n",
      "90:\tlearn: 0.0705089\ttotal: 2m 25s\tremaining: 2m 54s\n",
      "91:\tlearn: 0.0703486\ttotal: 2m 27s\tremaining: 2m 53s\n",
      "92:\tlearn: 0.0702397\ttotal: 2m 29s\tremaining: 2m 51s\n",
      "93:\tlearn: 0.0701179\ttotal: 2m 31s\tremaining: 2m 50s\n",
      "94:\tlearn: 0.0700299\ttotal: 2m 32s\tremaining: 2m 48s\n",
      "95:\tlearn: 0.0699074\ttotal: 2m 34s\tremaining: 2m 47s\n",
      "96:\tlearn: 0.0697874\ttotal: 2m 36s\tremaining: 2m 45s\n",
      "97:\tlearn: 0.0697044\ttotal: 2m 37s\tremaining: 2m 44s\n",
      "98:\tlearn: 0.0695788\ttotal: 2m 39s\tremaining: 2m 42s\n",
      "99:\tlearn: 0.0694714\ttotal: 2m 40s\tremaining: 2m 40s\n",
      "100:\tlearn: 0.0693974\ttotal: 2m 42s\tremaining: 2m 39s\n",
      "101:\tlearn: 0.0692895\ttotal: 2m 44s\tremaining: 2m 37s\n",
      "102:\tlearn: 0.0692167\ttotal: 2m 45s\tremaining: 2m 36s\n",
      "103:\tlearn: 0.0690972\ttotal: 2m 47s\tremaining: 2m 34s\n",
      "104:\tlearn: 0.0689976\ttotal: 2m 48s\tremaining: 2m 32s\n",
      "105:\tlearn: 0.0688841\ttotal: 2m 50s\tremaining: 2m 31s\n",
      "106:\tlearn: 0.0687892\ttotal: 2m 52s\tremaining: 2m 29s\n",
      "107:\tlearn: 0.0686591\ttotal: 2m 53s\tremaining: 2m 27s\n",
      "108:\tlearn: 0.0685189\ttotal: 2m 55s\tremaining: 2m 26s\n",
      "109:\tlearn: 0.0683968\ttotal: 2m 56s\tremaining: 2m 24s\n",
      "110:\tlearn: 0.0682805\ttotal: 2m 58s\tremaining: 2m 23s\n",
      "111:\tlearn: 0.0681805\ttotal: 3m\tremaining: 2m 21s\n",
      "112:\tlearn: 0.0681053\ttotal: 3m 1s\tremaining: 2m 20s\n",
      "113:\tlearn: 0.0679682\ttotal: 3m 3s\tremaining: 2m 18s\n",
      "114:\tlearn: 0.0678279\ttotal: 3m 5s\tremaining: 2m 16s\n",
      "115:\tlearn: 0.0677175\ttotal: 3m 6s\tremaining: 2m 15s\n",
      "116:\tlearn: 0.0676213\ttotal: 3m 8s\tremaining: 2m 13s\n",
      "117:\tlearn: 0.0675430\ttotal: 3m 10s\tremaining: 2m 12s\n",
      "118:\tlearn: 0.0673967\ttotal: 3m 11s\tremaining: 2m 10s\n",
      "119:\tlearn: 0.0672965\ttotal: 3m 13s\tremaining: 2m 9s\n",
      "120:\tlearn: 0.0672133\ttotal: 3m 15s\tremaining: 2m 7s\n",
      "121:\tlearn: 0.0671460\ttotal: 3m 17s\tremaining: 2m 6s\n",
      "122:\tlearn: 0.0670213\ttotal: 3m 19s\tremaining: 2m 4s\n",
      "123:\tlearn: 0.0669126\ttotal: 3m 21s\tremaining: 2m 3s\n",
      "124:\tlearn: 0.0668491\ttotal: 3m 23s\tremaining: 2m 1s\n",
      "125:\tlearn: 0.0667500\ttotal: 3m 25s\tremaining: 2m\n",
      "126:\tlearn: 0.0666550\ttotal: 3m 26s\tremaining: 1m 58s\n",
      "127:\tlearn: 0.0665878\ttotal: 3m 28s\tremaining: 1m 57s\n",
      "128:\tlearn: 0.0665089\ttotal: 3m 31s\tremaining: 1m 56s\n",
      "129:\tlearn: 0.0663884\ttotal: 3m 32s\tremaining: 1m 54s\n",
      "130:\tlearn: 0.0663152\ttotal: 3m 34s\tremaining: 1m 53s\n",
      "131:\tlearn: 0.0662231\ttotal: 3m 36s\tremaining: 1m 51s\n",
      "132:\tlearn: 0.0661454\ttotal: 3m 37s\tremaining: 1m 49s\n",
      "133:\tlearn: 0.0660671\ttotal: 3m 39s\tremaining: 1m 48s\n",
      "134:\tlearn: 0.0659716\ttotal: 3m 41s\tremaining: 1m 46s\n",
      "135:\tlearn: 0.0658800\ttotal: 3m 42s\tremaining: 1m 44s\n",
      "136:\tlearn: 0.0657649\ttotal: 3m 44s\tremaining: 1m 43s\n",
      "137:\tlearn: 0.0657016\ttotal: 3m 45s\tremaining: 1m 41s\n",
      "138:\tlearn: 0.0656042\ttotal: 3m 47s\tremaining: 1m 39s\n",
      "139:\tlearn: 0.0654933\ttotal: 3m 48s\tremaining: 1m 38s\n",
      "140:\tlearn: 0.0654049\ttotal: 3m 50s\tremaining: 1m 36s\n",
      "141:\tlearn: 0.0653539\ttotal: 3m 51s\tremaining: 1m 34s\n",
      "142:\tlearn: 0.0652938\ttotal: 3m 53s\tremaining: 1m 33s\n",
      "143:\tlearn: 0.0651881\ttotal: 3m 54s\tremaining: 1m 31s\n",
      "144:\tlearn: 0.0651341\ttotal: 3m 56s\tremaining: 1m 29s\n",
      "145:\tlearn: 0.0650338\ttotal: 3m 57s\tremaining: 1m 27s\n",
      "146:\tlearn: 0.0649493\ttotal: 3m 59s\tremaining: 1m 26s\n",
      "147:\tlearn: 0.0648415\ttotal: 4m\tremaining: 1m 24s\n",
      "148:\tlearn: 0.0647718\ttotal: 4m 2s\tremaining: 1m 22s\n",
      "149:\tlearn: 0.0647068\ttotal: 4m 3s\tremaining: 1m 21s\n",
      "150:\tlearn: 0.0646253\ttotal: 4m 5s\tremaining: 1m 19s\n",
      "151:\tlearn: 0.0645442\ttotal: 4m 6s\tremaining: 1m 17s\n",
      "152:\tlearn: 0.0644709\ttotal: 4m 8s\tremaining: 1m 16s\n",
      "153:\tlearn: 0.0643619\ttotal: 4m 9s\tremaining: 1m 14s\n",
      "154:\tlearn: 0.0642898\ttotal: 4m 11s\tremaining: 1m 13s\n",
      "155:\tlearn: 0.0642023\ttotal: 4m 12s\tremaining: 1m 11s\n",
      "156:\tlearn: 0.0641177\ttotal: 4m 14s\tremaining: 1m 9s\n",
      "157:\tlearn: 0.0640659\ttotal: 4m 15s\tremaining: 1m 8s\n",
      "158:\tlearn: 0.0639722\ttotal: 4m 17s\tremaining: 1m 6s\n",
      "159:\tlearn: 0.0638840\ttotal: 4m 18s\tremaining: 1m 4s\n",
      "160:\tlearn: 0.0638305\ttotal: 4m 20s\tremaining: 1m 3s\n",
      "161:\tlearn: 0.0637264\ttotal: 4m 21s\tremaining: 1m 1s\n",
      "162:\tlearn: 0.0636082\ttotal: 4m 23s\tremaining: 59.8s\n",
      "163:\tlearn: 0.0635520\ttotal: 4m 25s\tremaining: 58.2s\n",
      "164:\tlearn: 0.0634780\ttotal: 4m 26s\tremaining: 56.5s\n",
      "165:\tlearn: 0.0633925\ttotal: 4m 28s\tremaining: 54.9s\n",
      "166:\tlearn: 0.0633318\ttotal: 4m 29s\tremaining: 53.3s\n",
      "167:\tlearn: 0.0632457\ttotal: 4m 31s\tremaining: 51.6s\n",
      "168:\tlearn: 0.0631831\ttotal: 4m 32s\tremaining: 50s\n",
      "169:\tlearn: 0.0631181\ttotal: 4m 34s\tremaining: 48.4s\n",
      "170:\tlearn: 0.0630603\ttotal: 4m 35s\tremaining: 46.7s\n",
      "171:\tlearn: 0.0629850\ttotal: 4m 37s\tremaining: 45.1s\n",
      "172:\tlearn: 0.0628925\ttotal: 4m 38s\tremaining: 43.5s\n",
      "173:\tlearn: 0.0628461\ttotal: 4m 40s\tremaining: 41.9s\n",
      "174:\tlearn: 0.0627906\ttotal: 4m 41s\tremaining: 40.2s\n",
      "175:\tlearn: 0.0627194\ttotal: 4m 43s\tremaining: 38.6s\n",
      "176:\tlearn: 0.0626249\ttotal: 4m 44s\tremaining: 37s\n",
      "177:\tlearn: 0.0625865\ttotal: 4m 46s\tremaining: 35.4s\n",
      "178:\tlearn: 0.0625010\ttotal: 4m 47s\tremaining: 33.7s\n",
      "179:\tlearn: 0.0623979\ttotal: 4m 49s\tremaining: 32.1s\n",
      "180:\tlearn: 0.0622789\ttotal: 4m 50s\tremaining: 30.5s\n",
      "181:\tlearn: 0.0622158\ttotal: 4m 52s\tremaining: 28.9s\n",
      "182:\tlearn: 0.0621278\ttotal: 4m 53s\tremaining: 27.3s\n",
      "183:\tlearn: 0.0620677\ttotal: 4m 55s\tremaining: 25.7s\n",
      "184:\tlearn: 0.0620224\ttotal: 4m 56s\tremaining: 24s\n",
      "185:\tlearn: 0.0619570\ttotal: 4m 58s\tremaining: 22.4s\n",
      "186:\tlearn: 0.0618934\ttotal: 4m 59s\tremaining: 20.8s\n",
      "187:\tlearn: 0.0618363\ttotal: 5m 1s\tremaining: 19.2s\n",
      "188:\tlearn: 0.0617728\ttotal: 5m 2s\tremaining: 17.6s\n",
      "189:\tlearn: 0.0617048\ttotal: 5m 4s\tremaining: 16s\n",
      "190:\tlearn: 0.0616470\ttotal: 5m 5s\tremaining: 14.4s\n",
      "191:\tlearn: 0.0615695\ttotal: 5m 7s\tremaining: 12.8s\n",
      "192:\tlearn: 0.0614987\ttotal: 5m 8s\tremaining: 11.2s\n",
      "193:\tlearn: 0.0614171\ttotal: 5m 10s\tremaining: 9.6s\n",
      "194:\tlearn: 0.0613355\ttotal: 5m 11s\tremaining: 8s\n",
      "195:\tlearn: 0.0612881\ttotal: 5m 13s\tremaining: 6.4s\n",
      "196:\tlearn: 0.0612276\ttotal: 5m 14s\tremaining: 4.8s\n",
      "197:\tlearn: 0.0611855\ttotal: 5m 16s\tremaining: 3.2s\n",
      "198:\tlearn: 0.0611168\ttotal: 5m 17s\tremaining: 1.6s\n",
      "199:\tlearn: 0.0610633\ttotal: 5m 19s\tremaining: 0us\n",
      "CatBoost (Tuned) Accuracy: 0.9806, F1-score (weighted): 0.2011\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Load your data (replace 'your_data.csv' with your actual file path)\n",
    "data = pd.read_csv('C:/Users/alosh/Downloads/fall.csv')\n",
    "\n",
    "# Define the target variable (fall labels)\n",
    "target_variable = 'Tag'\n",
    "fall_labels = [1, 2, 3, 4]\n",
    "data['Fall'] = data[target_variable].isin(fall_labels).astype(int)  # Create new binary fall label\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = data[['AccX', 'AccY', 'AccZ']]\n",
    "y = data['Fall']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to train and evaluate models (reusable)\n",
    "def train_and_evaluate(model_name, model_class, params):\n",
    "  model = model_class(**params)\n",
    "  model.fit(X_train, y_train)\n",
    "  y_pred = model.predict(X_test)\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  f1 = f1_score(y_test, y_pred)\n",
    "  print(f\"{model_name} Accuracy: {accuracy:.4f}, F1-score (weighted): {f1:.4f}\")\n",
    "\n",
    "# Train and evaluate models\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(solver='liblinear')),\n",
    "    ('XGBoost', XGBClassifier(objective='binary:logistic')),\n",
    "    ('CatBoost', CatBoostClassifier(loss_function='Logloss', silent=True)),  # Consider adjusting CatBoost parameters\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(n_estimators=100))  # Experiment with n_estimators for GB\n",
    "]\n",
    "\n",
    "for model_name, model in models:\n",
    "  train_and_evaluate(model_name, model.__class__, getattr(model, 'get_params', lambda: model.params)())\n",
    "\n",
    "# Example hyperparameter tuning for CatBoost (optional)\n",
    "catboost_params = {\n",
    "    'learning_rate': 0.1,  # Adjust as needed\n",
    "    'depth': 16,  # Adjust as needed\n",
    "    'iterations': 200  # Adjust as needed\n",
    "}\n",
    "train_and_evaluate('CatBoost (Tuned)', CatBoostClassifier, catboost_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted fall-01-cam0-rgb.zip\n",
      "Extracted fall-01-cam1-rgb.zip\n",
      "Extracted fall-02-cam0-rgb.zip\n",
      "Extracted fall-02-cam1-rgb.zip\n",
      "Extracted fall-03-cam0-rgb.zip\n",
      "Extracted fall-03-cam1-rgb.zip\n",
      "Extracted fall-04-cam0-rgb.zip\n",
      "Extracted fall-04-cam1-rgb.zip\n",
      "Extracted fall-05-cam0-rgb.zip\n",
      "Extracted fall-05-cam1-rgb.zip\n",
      "Extracted fall-06-cam0-rgb.zip\n",
      "Extracted fall-06-cam1-rgb.zip\n",
      "Extracted fall-07-cam0-rgb.zip\n",
      "Extracted fall-07-cam1-rgb.zip\n",
      "Extracted fall-08-cam0-rgb.zip\n",
      "Extracted fall-08-cam1-rgb.zip\n",
      "Extracted fall-09-cam0-rgb.zip\n",
      "Extracted fall-09-cam1-rgb.zip\n",
      "Extracted fall-10-cam0-rgb.zip\n",
      "Extracted fall-10-cam1-rgb.zip\n",
      "Extracted fall-11-cam0-rgb.zip\n",
      "Extracted fall-11-cam1-rgb.zip\n",
      "Extracted fall-12-cam0-rgb.zip\n",
      "Extracted fall-12-cam1-rgb.zip\n",
      "Extracted fall-13-cam0-rgb.zip\n",
      "Extracted fall-13-cam1-rgb.zip\n",
      "Extracted fall-14-cam0-rgb.zip\n",
      "Extracted fall-14-cam1-rgb.zip\n",
      "Extracted fall-15-cam0-rgb.zip\n",
      "Extracted fall-15-cam1-rgb.zip\n",
      "Extracted fall-16-cam0-rgb.zip\n",
      "Extracted fall-16-cam1-rgb.zip\n",
      "Extracted fall-17-cam0-rgb.zip\n",
      "Extracted fall-17-cam1-rgb.zip\n",
      "Extracted fall-18-cam0-rgb.zip\n",
      "Extracted fall-18-cam1-rgb.zip\n",
      "Extracted fall-19-cam0-rgb.zip\n",
      "Extracted fall-19-cam1-rgb.zip\n",
      "Extracted fall-20-cam0-rgb.zip\n",
      "Extracted fall-20-cam1-rgb.zip\n",
      "Extracted fall-21-cam0-rgb.zip\n",
      "Extracted fall-21-cam1-rgb.zip\n",
      "Extracted fall-22-cam0-rgb.zip\n",
      "Extracted fall-22-cam1-rgb.zip\n",
      "Extracted fall-23-cam0-rgb.zip\n",
      "Extracted fall-23-cam1-rgb.zip\n",
      "Extracted fall-24-cam0-rgb.zip\n",
      "Extracted fall-24-cam1-rgb.zip\n",
      "Extracted fall-25-cam0-rgb.zip\n",
      "Extracted fall-25-cam1-rgb.zip\n",
      "Extracted fall-26-cam0-rgb.zip\n",
      "Extracted fall-26-cam1-rgb.zip\n",
      "Extracted fall-27-cam0-rgb.zip\n",
      "Extracted fall-27-cam1-rgb.zip\n",
      "Extracted fall-28-cam0-rgb.zip\n",
      "Extracted fall-28-cam1-rgb.zip\n",
      "Extracted fall-29-cam0-rgb.zip\n",
      "Extracted fall-29-cam1-rgb.zip\n",
      "Extracted fall-30-cam0-rgb.zip\n",
      "Extracted fall-30-cam1-rgb.zip\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Function to unzip files in a directory\n",
    "def unzip_files(folder_path):\n",
    "    # Iterate over all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        # Check if the file is a zip file\n",
    "        if zipfile.is_zipfile(filepath):\n",
    "            # Open the zip file\n",
    "            with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
    "                # Extract all contents to the same directory\n",
    "                zip_ref.extractall(folder_path)\n",
    "                print(f\"Extracted {filename}\")\n",
    "\n",
    "# Example usage:\n",
    "folder_path = r'C:\\Users\\alosh\\Downloads\\FallDataset'  # Replace with the path to your folder of zip files\n",
    "unzip_files(folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
